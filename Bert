# Bert

Bert is google's new technique for NLP pre-training called Bidirectional Encoder Representations from Transformers. Compares with privious model, Bert achieve the goal that
sdasdfdsadf 